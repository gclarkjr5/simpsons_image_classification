{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 47)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local directory\n",
    "# train_directory = '/media/sf_Gee_Hard_Drive/Kaggle Data/the-simpsons-characters-dataset/simpsons_train_scaled'\n",
    "\n",
    "# AWS directory\n",
    "train_directory = '../simpsons_train_scaled'\n",
    "\n",
    "def getClasses(directory):\n",
    "    dirs = os.listdir(train_directory)\n",
    "    indices = np.arange(len(dirs))\n",
    "    dictionary = dict(zip(dirs, indices))\n",
    "    return(dictionary, dirs)\n",
    "\n",
    "classes, characters = getClasses(train_directory)\n",
    "len(classes), len(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-950a12b2c077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpixArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpixArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpixArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixArray\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharacter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixArray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrainList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Directory\n",
    "trainList = list()\n",
    "for character in characters:\n",
    "    folder = train_directory + '/' + character\n",
    "    files = os.listdir(folder)\n",
    "    for file in files:\n",
    "        filePath = folder + '/' + file\n",
    "        pixArray = imageio.imread(filePath)\n",
    "        pixArray = np.array(pixArray)\n",
    "        pixArray = pixArray.flatten()\n",
    "        pixArray = pixArray/255\n",
    "        l = [classes[character], character, pixArray]\n",
    "        trainList.append(l)\n",
    "\n",
    "len(trainList), len(trainList[0]), trainList[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Directory\n",
    "\n",
    "# AWS directory\n",
    "test_directory = '../simpsons_test_scaled'\n",
    "\n",
    "testList = list()\n",
    "test_pics = os.listdir(test_directory)\n",
    "# ids = []\n",
    "for pic in test_pics:\n",
    "    if pic != '.DS_Store':\n",
    "        filePath = test_directory + '/' + pic\n",
    "        pixArray = imageio.imread(filePath)\n",
    "        pixArray = np.array(pixArray)\n",
    "        pixArray = pixArray.flatten()\n",
    "        pixArray = pixArray/255\n",
    "        character = re.sub('_[0-9]{1,2}.jpg$', '', pic)\n",
    "        l = [classes[character], character, pixArray]\n",
    "        testList.append(l)\n",
    "        \n",
    "#         ids.append([pix_array, character_label, class_dict[character_label]])\n",
    "# testObj = np.array(ids)\n",
    "# testObj.shape, testObj[0][0].shape\n",
    "len(testList), len(testList[0]), testList[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = list(map(lambda x: x[2], trainList))\n",
    "YTrain = list(map(lambda x: x[0], trainList))\n",
    "XTest = list(map(lambda x: x[2], testList))\n",
    "YTest = list(map(lambda x: x[0], testList))\n",
    "\n",
    "\n",
    "X_train, Y_train = shuffle(XTrain, YTrain, random_state = 15)\n",
    "X_test, Y_test = shuffle(XTest, YTest, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split on sample training data\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "# Grid Search\n",
    "# parameters = {\n",
    "#     'solver': ['lbfgs', 'sag', 'newton-cg']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class=\"multinomial\", solver = \"newton-cg\")\n",
    "# clf = GridSearchCV(logR, parameters)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09797979797979799"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = clf.score(X_test, Y_test)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
